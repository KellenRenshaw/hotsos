import os

import statistics

from datetime import datetime


class LogSequenceCollection(object):
    """This class is used by the LogSequenceBase class to identify and
    collect log seqeunces defined by a start and end point.

    Sequences can span multiple files and are identified by an "event_id" which
    itself does not have to be unique and as such event_ids are tracked using
    unique identifiers.
    """
    def __init__(self):
        """Get stats on the collected sequences. We refer to sequences as
        samples in the results."""
        self._sequences = {}
        self._incomplete_sequences = {}
        self.sequence_end_unique_ids = {}
        self.sequence_start_unique_ids = {}

    def has_complete_sequences(self):
        for s in self._sequences:
            if "start" in self._sequences[s]:
                return True

        return False

    @property
    def complete_sequences(self):
        sequences = {}
        for s in self._sequences:
            if "start" in self._sequences[s]:
                sequences[s] = self._sequences[s]

        return sequences

    @property
    def incomplete_sequences(self):
        return self._incomplete_sequences

    def update_sequence(self, sequence_id, key, value):
        self._sequences[sequence_id][key] = value

    def add_sequence_end(self, key, end):
        if key in self.sequence_end_unique_ids:
            self.sequence_end_unique_ids[key] += 1
        else:
            self.sequence_end_unique_ids[key] = 0

        seq_key = self.sequence_end_unique_ids[key]
        sequence_id = "{}_{}".format(seq_key, key)

        self._sequences[sequence_id] = {"end": end}
        return sequence_id

    def add_sequence_start(self, key, data, metadata=None, metadata_key=None):
        if key not in self.sequence_end_unique_ids:
            # cant add start for non-existant ending so store incomplete
            # sequence and return.
            self._incomplete_sequences[key] = data
            return

        # get new start id
        seq_key = self.sequence_start_unique_ids.get(key, -1)
        if seq_key >= 0:
            seq_key += 1
        else:
            seq_key = 0

        sequence_id = "{}_{}".format(seq_key, key)

        # We only add start if end already found. If this is not the case it
        # could be an interrupted sequence or EOF.
        if sequence_id not in self._sequences:
            return

        self.sequence_start_unique_ids[key] = seq_key
        self._sequences[sequence_id]["start"] = data
        if metadata:
            if not metadata_key:
                metadata_key = "metadata"

            self._sequences[sequence_id][metadata_key] = metadata

        return sequence_id

    def get_sequence(self, sequence_id):
        return self._sequences[sequence_id]


class SearchResultIndices(object):
    def __init__(self, day_idx=1, secs_idx=2, event_id_idx=3,
                 metadata_idx=None, metadata_key=None):
        """
        This is used to know where to find required information within a
        SearchResult. The indexes refer to python.re groups.

        The minimum required information that a result must contain is day,
        secs and event_id. Results will be referred to using whatever event_id
        is set to.
        """
        self.day = day_idx
        self.secs = secs_idx
        self.event_id = event_id_idx
        self.metadata = metadata_idx
        self.metadata_key = metadata_key


class LogSequenceBase(object):
    """This base class is used to identify sequences within logs whereby a
    sequence has a start and end point. It can thenbe implemented by other
    classes to perform further analysis on sequence data.

    This class supports overlapping sequences e.g. for scenarios where logs
    are generated by parallal tasks.
    """

    def __init__(self, results, results_tag_prefix, custom_idxs=None):
        """
        @param results: FileSearcher results. This will be searched using
                        <results_tag_prefix>-start and <results_tag_prefix>-end
        @param results_tag_prefix: prefix of tag used for search results for
                                   sequences start and end.
        @param custom_idxs: optionally provide custom SearchResultIndices.
        """
        self.data = LogSequenceCollection()
        self.results = results
        self.results_tag_prefix = results_tag_prefix
        if custom_idxs:
            log_seq_idxs = custom_idxs
        else:
            log_seq_idxs = SearchResultIndices()

        self.log_seq_idxs = log_seq_idxs

    def get_sequences(self):
        """ First collect matched sequence endings then relate with their
        corresponding start event to form complete sequences.
        """
        seq_idxs = self.log_seq_idxs

        end_tag = "{}-end".format(self.results_tag_prefix)
        for result in self.results.find_by_tag(end_tag):
            day = result.get(seq_idxs.day)
            secs = result.get(seq_idxs.secs)
            event_id = result.get(seq_idxs.event_id)
            end = "{} {}".format(day, secs)
            end = datetime.strptime(end, "%Y-%m-%d %H:%M:%S.%f")

            # event_id may have many updates over time across many files so we
            # need to have a way to make them unique.
            key = "{}_{}".format(os.path.basename(result.source), event_id)
            sequence_id = self.data.add_sequence_end(key, end)

        start_tag = "{}-start".format(self.results_tag_prefix)
        for result in self.results.find_by_tag(start_tag):
            day = result.get(seq_idxs.day)
            secs = result.get(seq_idxs.secs)
            event_id = result.get(seq_idxs.event_id)
            start = "{} {}".format(day, secs)
            start = datetime.strptime(start, "%Y-%m-%d %H:%M:%S.%f")
            metadata = result.get(seq_idxs.metadata)
            meta_key = seq_idxs.metadata_key
            key = "{}_{}".format(os.path.basename(result.source), event_id)
            sequence_id = self.data.add_sequence_start(key, start,
                                                       metadata=metadata,
                                                       metadata_key=meta_key)
            if not sequence_id:
                """
                Indicates an incomplete sequence i.e. one that has a start but
                no end.
                """
                continue

            sequence = self.data.get_sequence(sequence_id)
            if not sequence:
                continue

            end = sequence.get("end", None)
            etime = end - start
            if etime.total_seconds() < 0:
                # this is probably a broken or invalid sequence so we
                # set ingore it.
                continue

            duration = round(float(etime.total_seconds()), 2)
            self.data.update_sequence(sequence_id, "duration", duration)

        if not self.data.has_complete_sequences():
            return

    def __call__(self):
        self.get_sequences()


class LogSequenceStats(LogSequenceBase):
    """ This class provides statistical information on log sequences."""

    def get_top_sequences(self, max, sort_by_key, reverse=False):
        count = 0
        top_n = {}
        top_n_sorted = {}

        valid_sequences = {}
        for k, v in self.data.complete_sequences.items():
            if v.get(sort_by_key):
                valid_sequences[k] = v

        for k, v in sorted(valid_sequences.items(),
                           key=lambda x: x[1].get(sort_by_key, 0),
                           reverse=reverse):
            # skip unterminated entries (e.g. on file wraparound)
            if "start" not in v:
                continue

            if count >= max:
                break

            count += 1
            top_n[k] = v

        for k, v in sorted(top_n.items(), key=lambda x: x[1]["start"],
                           reverse=reverse):
            event_id = k.rpartition('_')[2]
            event_id = event_id.partition('_')[0]
            top_n_sorted[event_id] = {"start": v["start"],
                                      "end": v["end"]}
            if v.get("duration"):
                top_n_sorted[event_id]["duration"] = v["duration"]

            metadata_key = self.log_seq_idxs.metadata_key
            if v.get(metadata_key):
                top_n_sorted[event_id][metadata_key] = v[metadata_key]

        return top_n_sorted

    def get_top_n_sorted(self, max):
        return self.get_top_sequences(max, sort_by_key="duration",
                                      reverse=True)

    def get_stats(self, key):
        if not self.data.has_complete_sequences():
            return

        sequences = self.data.complete_sequences.values()
        # ignore sequences with a duration None since they are invalid
        sequences = [s.get(key) for s in sequences if s.get(key) is not None]
        stats = {'min': round(min(sequences), 2),
                 'max': round(max(sequences), 2),
                 'stdev': round(statistics.pstdev(sequences), 2),
                 'avg': round(statistics.mean(sequences), 2),
                 'samples': len(sequences)}

        if self.data.incomplete_sequences:
            stats['incomplete'] = len(self.data.incomplete_sequences.values())

        return stats
